{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, date\n",
    "import pickle\n",
    "\n",
    "Countries_indexes = [\"EUSA\", \"EWC\", \"EWU\", \"EWG\", \"EWQ\", \"EWJ\", \"MCHI\", \"INDA\", \"EWA\", \"EWY\", \"EWW\", \"EWL\", \"EWT\", \"EWH\", \"EWS\", \"EWI\", \"EWP\", \"EWN\", \"EWD\", \"EWO\", \"EWK\", \"EDEN\", \"EFNL\", \"EIS\", \"EWZ\"]\n",
    "# Compute returns function in Polars\n",
    "def compute_returns(df, price_col=\"weighted-avg-price\", lag=1):\n",
    "    return df.with_columns(\n",
    "        (pl.col(price_col).diff(lag) / pl.col(price_col).shift(lag)).alias(\"return\")\n",
    "    ).drop_nulls(subset=[\"return\"])\n",
    "\n",
    "\n",
    "def rolling_cross_correlation(df1, df2, column1, column2, window_length, delta_step=5):\n",
    "    \"\"\"\n",
    "    Compute rolling cross-correlation between two DataFrames.\n",
    "    \n",
    "    Parameters:\n",
    "    - df1, df2: Polars DataFrames\n",
    "    - column1, column2: Column names to correlate\n",
    "    - window_length: Size of the rolling window\n",
    "    - delta_step: Sliding window step size\n",
    "    \n",
    "    Returns:\n",
    "    Polars DataFrame with correlation results\n",
    "    \"\"\"\n",
    "    # Convert to NumPy for correlation computation\n",
    "    arr1 = df1[column1].to_numpy()\n",
    "    arr2 = df2[column2].to_numpy()\n",
    "\n",
    "    # non_zero_mask = ~((arr1 == 0) & (arr2 == 0))\n",
    "\n",
    "    # # Apply the mask to arr1 and arr2\n",
    "    # arr1 = arr1[non_zero_mask]\n",
    "    # arr2 = arr2[non_zero_mask]\n",
    "    \n",
    "    correlations = []\n",
    "    window_starts = []\n",
    "    covariances = []\n",
    "    \n",
    "    # Slide window with specified delta step\n",
    "    for start in range(0, min(len(arr1),len(arr2)) - window_length + 1, delta_step):\n",
    "        end = start + window_length\n",
    "        window_start = start\n",
    "        \n",
    "        window1 = arr1[start:end]\n",
    "        window2 = arr2[start:end]\n",
    "        \n",
    "        # Compute correlation for the current window\n",
    "        correlation = np.corrcoef(window1, window2)[0, 1]\n",
    "        cov = np.cov(window1, window2)[0, 1]\n",
    "\n",
    "        covariances.append(cov)\n",
    "        correlations.append(correlation)\n",
    "        window_starts.append(window_start)\n",
    "    \n",
    "    # Create Polars DataFrame with results\n",
    "    result_df = pl.DataFrame({\n",
    "        \"window_start\": window_starts,\n",
    "        \"correlation\": correlations,\n",
    "        \"covariance\": covariances\n",
    "    })\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "#  Function to compute rolling correlation for all pairs\n",
    "def compute_all_pairs_rolling_correlation(countries, window_length=60, delta_step=5):\n",
    "    results = {}\n",
    "    for i in tqdm(range(len(countries))):\n",
    "        for j in range(i + 1, len(countries)):\n",
    "            country1 = countries[i]\n",
    "            country2 = countries[j]\n",
    "            print(f\"Computing rolling correlation for {country1} and {country2}...\")\n",
    "            # Load data for the two countries\n",
    "            df1 = pl.read_parquet(f\"Data/clean/{country1}.parquet\")\n",
    "            df2 = pl.read_parquet(f\"Data/clean/{country2}.parquet\")\n",
    "\n",
    "            ret_df1 = compute_returns(df1)\n",
    "            ret_df2 = compute_returns(df2)\n",
    "            \n",
    "            # Compute rolling correlation\n",
    "            rolling_corr_df = rolling_cross_correlation(\n",
    "                ret_df1, ret_df2, \n",
    "                column1=\"return\", column2=\"return\", \n",
    "                window_length=window_length, \n",
    "                delta_step=delta_step,\n",
    "            )\n",
    "            \n",
    "            # Drop NaNs and compute mean correlation\n",
    "            # rolling_corr_df = rolling_corr_df.fill_nan(None)   \n",
    "            # rolling_corr_df = rolling_corr_df.drop_nulls()\n",
    "            # mean_corr = rolling_corr_df[\"correlation\"].mean()\n",
    "            \n",
    "            # Store the result\n",
    "            results[(country1, country2)] = rolling_corr_df\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Compute rolling correlation for all pairs in Countries_indexes\n",
    "\n",
    "all_pairs_rolling_corr = compute_all_pairs_rolling_correlation((\"EUSA\",\"EWC\"), window_length=60, delta_step=5)\n",
    "print(all_pairs_rolling_corr)\n",
    "with open('all_pairs_rolling_corr.pkl', 'wb') as f:\n",
    "    pickle.dump(all_pairs_rolling_corr, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
